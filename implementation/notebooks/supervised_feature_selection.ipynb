{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d2cad9",
   "metadata": {},
   "source": [
    "# Supervised Feature Selection (Section 5.1)\n",
    "\n",
    "This notebook recreates the supervised feature selection experiment on the Parkinsons dataset as described in Section 5.1 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e08a9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add implementation/src to path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6367e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from scipy.stats import entropy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.special import gamma,psi,digamma\n",
    "from numpy import pi\n",
    "import math\n",
    "import os\n",
    "from numpy import linalg as LA\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd7a01",
   "metadata": {},
   "source": [
    "# Ross 2014 Estimators (Entropy & Mutual Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "675dc309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information_continuous_discrete(x, y, k):\n",
    "    \"\"\"\n",
    "    Calculates the mututal information between a continuous vector x and a\n",
    "    disrete class vector y.\n",
    "    This implementation can calculate the MI between the joint distribution of\n",
    "    one or more continuous variables (X[:, 1:3]) with a discrete variable (y).\n",
    "    Thanks to Adam Pocock, the author of the FEAST package for the idea.\n",
    "    Brian C. Ross, 2014, PLOS ONE\n",
    "    Mutual Information between Discrete and Continuous Data Sets\n",
    "    \"\"\"\n",
    "\n",
    "    y = y.flatten()\n",
    "    n = x.shape[0]\n",
    "    classes = np.unique(y)\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    # distance to kth in-class neighbour\n",
    "    d2k = np.empty(n)\n",
    "    # number of points within each point's class\n",
    "    Nx = []\n",
    "    for yi in y:\n",
    "        Nx.append(np.sum(y == yi))\n",
    "\n",
    "    # find the distance of the kth in-class point\n",
    "    for c in classes:\n",
    "        mask = np.where(y == c)[0]\n",
    "        knn.fit(x[mask, :])\n",
    "        d2k[mask] = knn.kneighbors()[0][:, -1]\n",
    "\n",
    "    # find the number of points within the distance of the kth in-class point\n",
    "    knn.fit(x)\n",
    "    m = knn.radius_neighbors(radius=d2k, return_distance=False)\n",
    "    m = [i.shape[0] for i in m]\n",
    "\n",
    "    # calculate MI based on Equation 2 in Ross 2014\n",
    "    MI = psi(n) - np.mean(psi(Nx)) + psi(k) - np.mean(psi(m))\n",
    "    return MI\n",
    "\n",
    "\n",
    "def nearest_distances(X, k=1):\n",
    "    \"\"\"\n",
    "    Returns the distance to the kth nearest neighbor for every point in X\n",
    "    \"\"\"\n",
    "\n",
    "    knn = NearestNeighbors(n_neighbors=k, metric=\"chebyshev\")\n",
    "    knn.fit(X)\n",
    "    # the first nearest neighbor is itself\n",
    "    d, _ = knn.kneighbors(X)\n",
    "    # returns the distance to the kth nearest neighbor\n",
    "    return d[:, -1]\n",
    "\n",
    "\n",
    "def entropy(X, k=1):\n",
    "    \"\"\"\n",
    "    Returns the entropy of the X.\n",
    "    Written by Gael Varoquaux:\n",
    "    https://gist.github.com/GaelVaroquaux/ead9898bd3c973c40429\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        The data the entropy of which is computed\n",
    "    k : int, optional\n",
    "        number of nearest neighbors for density estimation\n",
    "    References\n",
    "    ----------\n",
    "    Kozachenko, L. F. & Leonenko, N. N. 1987 Sample estimate of entropy\n",
    "    of a random vector. Probl. Inf. Transm. 23, 95-101.\n",
    "    See also: Evans, D. 2008 A computationally efficient estimator for\n",
    "    mutual information, Proc. R. Soc. A 464 (2093), 1203-1215.\n",
    "    and:\n",
    "    Kraskov A, Stogbauer H, Grassberger P. (2004). Estimating mutual\n",
    "    information. Phys Rev E 69(6 Pt 2):066138.\n",
    "    F. Perez-Cruz, (2008). Estimation of Information Theoretic Measures\n",
    "    for Continuous Random Variables. Advances in Neural Information\n",
    "    Processing Systems 21 (NIPS). Vancouver (Canada), December.\n",
    "    return d*mean(log(r))+log(volume_unit_ball)+log(n-1)-log(k)\n",
    "    \"\"\"\n",
    "\n",
    "    # Distance to kth nearest neighbor\n",
    "    r = nearest_distances(X, k)\n",
    "    n, d = X.shape\n",
    "    volume_unit_ball = (np.pi ** (0.5 * d)) / gamma(0.5 * d + 1)\n",
    "    return (\n",
    "        d * np.mean(np.log(r + np.finfo(X.dtype).eps))\n",
    "        + np.log(volume_unit_ball)\n",
    "        + psi(n)\n",
    "        - psi(k)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114dda9",
   "metadata": {},
   "source": [
    "# Calculate $\\rho$ and $Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "92db62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rho_and_Q(seed):\n",
    "    df = pd.read_csv(\"../data/parkinsons.data\")\n",
    "    a = df.loc[:, df.columns != \"status\"].values[:, 1:]\n",
    "    b = df.loc[:, \"status\"].values\n",
    "    features = df.loc[:, df.columns != \"status\"].values[:, 1:].reshape(195, 22)\n",
    "    labels = df.loc[:, \"status\"].values.reshape(195, 1)\n",
    "    df = np.hstack((features, labels))\n",
    "    df = pd.DataFrame(\n",
    "        df,\n",
    "        columns=[\n",
    "            \"MDVP:Fo(Hz)\",\n",
    "            \"MDVP:Fhi(Hz)\",\n",
    "            \"MDVP:Flo(Hz)\",\n",
    "            \"MDVP:Jitter(%)\",\n",
    "            \"MDVP:Jitter(Abs)\",\n",
    "            \"MDVP:RAP\",\n",
    "            \"MDVP:PPQ\",\n",
    "            \"Jitter:DDP\",\n",
    "            \"MDVP:Shimmer\",\n",
    "            \"MDVP:Shimmer(dB)\",\n",
    "            \"Shimmer:APQ3\",\n",
    "            \"Shimmer:APQ5\",\n",
    "            \"MDVP:APQ\",\n",
    "            \"Shimmer:DDA\",\n",
    "            \"NHR\",\n",
    "            \"HNR\",\n",
    "            \"RPDE\",\n",
    "            \"DFA\",\n",
    "            \"spread1\",\n",
    "            \"spread2\",\n",
    "            \"D2\",\n",
    "            \"PPE\",\n",
    "            \"status\",\n",
    "        ],\n",
    "    )\n",
    "    print(labels.shape, features.shape)\n",
    "    p_ig = mutual_info_classif(features, labels.reshape(-1), random_state=seed)  # 1x22\n",
    "\n",
    "    # p_fs = fisher_score.fisher_score(features,labels)\n",
    "    Q = np.zeros((22, 22))\n",
    "    k = 5  # 7\n",
    "    for i in range(22):\n",
    "        for j in range(22):\n",
    "            H = entropy(\n",
    "                np.array([a[:, i]], dtype=\"float64\").reshape(195, 1), k\n",
    "            ) + entropy(np.array([a[:, j]], dtype=\"float64\").reshape(195, 1), k)\n",
    "            # print(np.array(features[:,i]).reshape(1,195).shape)\n",
    "            # print(np.vstack((features[:,i],features[:,j])).T.shape)\n",
    "            tmp1 = mutual_information_continuous_discrete(\n",
    "                np.array(features[:, i]).reshape(1, 195).T, labels, k\n",
    "            )\n",
    "            tmp2 = mutual_information_continuous_discrete(\n",
    "                np.array(features[:, j]).reshape(1, 195).T, labels, k\n",
    "            )\n",
    "            # print(tmp1)\n",
    "            # print(np.vstack((features[:,i],features[:,j])).T)\n",
    "            tmp3 = mutual_information_continuous_discrete(\n",
    "                np.vstack((features[:, i], features[:, j])).T, labels, k\n",
    "            )\n",
    "            tmp = tmp1 + tmp2 - tmp3\n",
    "            # print(tmp1+tmp2-tmp3)\n",
    "            Q[i, j] = max(0, tmp / H)\n",
    "    \n",
    "    w, _ = LA.eig(Q)\n",
    "    w\n",
    "    xi = -min(0,min(w))\n",
    "    Q = xi * np.eye(22) + Q\n",
    "    return np.array(p_ig), Q, features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3c23669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_objective(Q, rho):\n",
    "    \"\"\"\n",
    "    return f(w) = (w^T Q w) / (rho^T w)\n",
    "    \"\"\"\n",
    "    def fractional_objective(w):\n",
    "        num = w.T @ Q @ w\n",
    "        den = rho.T @ w\n",
    "        return num / den\n",
    "    return fractional_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "419702fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195, 1) (195, 22)\n",
      "(195, 1) (195, 22)\n",
      "(195, 1) (195, 22)\n",
      "(195, 1) (195, 22)\n",
      "(195, 1) (195, 22)\n",
      "(195, 1) (195, 22)\n",
      "(195, 1) (195, 22)\n",
      "(195, 1) (195, 22)\n",
      "(195, 1) (195, 22)\n",
      "(195, 1) (195, 22)\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import Bounds, LinearConstraint\n",
    "from algorithms import Projector, GDA\n",
    "import autograd.numpy as anp\n",
    "\n",
    "results = []\n",
    "\n",
    "for seed in range(1, 100, 10):\n",
    "    rho, Q, X, y = calculate_rho_and_Q(seed)\n",
    "\n",
    "\n",
    "    def f(x):\n",
    "        return (anp.dot(anp.dot(x,Q),x.T))/(anp.dot(rho,x.T))\n",
    "\n",
    "    \n",
    "    n_features = len(rho)\n",
    "\n",
    "    bounds = Bounds([0] * n_features, [np.inf] * n_features)\n",
    "    constraints = [\n",
    "        LinearConstraint(np.ones((1, n_features)), [1], [1])  # sum(w) = 1\n",
    "    ]\n",
    "    projector = Projector(bounds, constraints)\n",
    "    f = make_objective(Q, rho)\n",
    "    gda = GDA(function=f, projector=projector)\n",
    "    w_init = np.ones(n_features) / n_features\n",
    "\n",
    "    from scipy.optimize import minimize\n",
    "\n",
    "    start = time.time()\n",
    "    res_scipy = minimize(fun=f, x0=w_init, method='SLSQP', bounds=bounds, constraints=constraints, tol=1e-12)\n",
    "    res_scipy.f_opt = f(res_scipy.x)\n",
    "    time_scipy = time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    res_gda = gda.solve(w_init, tol=1e-12)\n",
    "    time_gda = time.time() - start\n",
    "\n",
    "    results.append((seed, res_gda, time_gda, res_scipy, time_scipy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d80ac9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                                       Comparing Scipy vs GDA                                       |\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "| seed   |          Algorithm GDA (proposed)           |                    Scipy                    |\n",
      "+--------+---------------------------------------------+---------------------------------------------+\n",
      "|        |      f_opt       |  time (ms)  |   iters    |      f_opt       |  time (ms)  |   iters    |\n",
      "+--------+------------------+-------------+------------+------------------+-------------+------------+\n",
      "|      1 |         0.152478 |    0.018614 |         32 |         0.152478 |    0.006164 |         19 |\n",
      "|     11 |         0.153480 |    0.096673 |         51 |         0.153480 |    0.030229 |         15 |\n",
      "|     21 |         0.153834 |    0.015980 |         31 |         0.153834 |    0.006214 |         18 |\n",
      "|     31 |         0.153501 |    0.029897 |         55 |         0.153501 |    0.005530 |         16 |\n",
      "|     41 |         0.154281 |    0.026025 |         50 |         0.154281 |    0.004012 |         13 |\n",
      "|     51 |         0.154185 |    0.031173 |         60 |         0.154185 |    0.005908 |         15 |\n",
      "|     61 |         0.154878 |    0.034290 |         57 |         0.154878 |    0.006208 |         16 |\n",
      "|     71 |         0.153465 |    0.021693 |         33 |         0.153465 |    0.005638 |         16 |\n",
      "|     81 |         0.153517 |    0.031792 |         59 |         0.153517 |    0.003538 |         13 |\n",
      "|     91 |         0.153269 |    0.030206 |         52 |         0.153269 |    0.005027 |         15 |\n",
      "+--------+------------------+-------------+------------+------------------+-------------+------------+\n"
     ]
    }
   ],
   "source": [
    "# Draw a table comparing the two results\n",
    "title = \"Comparing Scipy vs GDA\"\n",
    "\n",
    "print(f\"+{'-' * 100}+\")\n",
    "print(f\"|{title:^100}|\")\n",
    "print(f\"+{'-' * 100}+\")\n",
    "# Print a table of results with f opt, time, iters\n",
    "print(f\"|{'seed':^7} | {'Algorithm GDA (proposed)':^43} | {'Scipy':^43} |\")\n",
    "print(f\"+{'-' * 8}+{'-' * 45}+{'-' * 45}+\")\n",
    "print(f\"|{'':>7} | {'f_opt':^16} | {'time (ms)':^11} | {'iters':^10} | {'f_opt':^16} | {'time (ms)':^11} | {'iters':^10} |\")\n",
    "print(f\"+{'-' * 8}+{'-' * 18}+{'-' * 13}+{'-' * 12}+{'-' * 18}+{'-' * 13}+{'-' * 12}+\")\n",
    "for n, res_gda, time_gda, res_scipy, time_scipy in results:\n",
    "    print(f\"| {n:6d} | {res_gda.f_opt:16.6f} | {time_gda:11.6f} | {len(res_gda.x_history):10d} | {res_scipy.f_opt:16.6f} | {time_scipy:11.6f} | {(res_scipy.nit):10d} |\")\n",
    "print(f\"+{'-' * 8}+{'-' * 18}+{'-' * 13}+{'-' * 12}+{'-' * 18}+{'-' * 13}+{'-' * 12}+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636afd5f",
   "metadata": {},
   "source": [
    "Có thể thấy, mỗi lần chạy có kết quả khác nhau, do mutual_info_classif tạo random noise. Do đó implementation của paper thực sự không đáng tin cậy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algorithms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
